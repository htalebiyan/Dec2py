{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Interdependent Network Restoration Decision-making\n",
        "This notebook finds restoration plans for interdependent power and water in Seaside, OR, subject to different initial\n",
        "seismic damage scenarios. Centralized decision-making models are employed here. These methods solve one optimization\n",
        "problem for the whole interdependent network, which leads to the optimal restoration plan. Such models assume that the\n",
        "decision-maker is one entity that has complete information and authority to restore all layers of the interdependent\n",
        "network. These methods include Interdependent Network Design Problem (INDP) and time-dependent INDP (td-INDP)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import runutils\n",
        "import dindputils\n",
        "import plots\n",
        "import pickle"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Input/Output file addresses\n",
        "1. `BASE_DIR`: the address of the folder where the basic network information (topology, parameters, etc.) are stored\n",
        "2. `DAMAGE_DIR`: the address of the folder where the damage information are stored\n",
        "3. `OUTPUT_DIR`: the address of the folder where the output files should be written"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "BASE_DIR = \"C:/Users/ht20/Documents/GitHub/NIST_testbeds/Seaside/Node_arc_info/\"\n",
        "DAMAGE_DIR = \"C:/Users/ht20/Documents/GitHub/NIST_testbeds/Seaside/Damage_scenarios/eq_1000yr_initial_damage/\"\n",
        "OUTPUT_DIR = '../results/'"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " \n",
        "## Set analysis dictionaries \n",
        "1. `FAIL_SCE_PARAM`: stores information on the type of the damage scenario and network \n",
        "dataset. This dictionary should have the following items:\n",
        "    1. `TYPE`: type of the network, which is set to `from_csv` for Seaside networks.\n",
        "    2. `MAGS`: sets the earthquake return period.\n",
        "    3. `SAMPLE_RANGE`: sets the range of sample scenarios to be analyzed.\n",
        "    4. `BASE_DIR`: sets the folder where the basic network information is stored.\n",
        "    5. `DAMAGE_DIR`: sets the folder where the damage information is stored\n",
        "2. `DYNAMIC_PARAMS`: sets the features of the models that incorporate dynamic demand values (per dislocation models)\n",
        "into the analysis. Set it to *None* if you want to use static demand values (equal to the pre-event values) that are\n",
        "constant for different time steps. The dictionary should have the following items:\n",
        "    1. `TYPE`: type of the dislocation data (see below).\n",
        "    2. `RETURN`: type of the model for the return of the dislocated population. Options: *step_function* and *linear*.\n",
        "    3. `DIR`: sets the folder where the dislocation data are stored.\n",
        "    4. `TESTBED`: sets the name of the testbed in analysis.\n",
        "3. `EXTRA_COMMODITY`: Multi-commodity parameters dict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "FAIL_SCE_PARAM = {'TYPE': \"from_csv\", 'SAMPLE_RANGE': range(0, 1), 'MAGS': [1000],\n",
        "                  'FILTER_SCE': None, 'BASE_DIR': BASE_DIR, 'DAMAGE_DIR': DAMAGE_DIR}\n",
        "ROOT_DISLOC = \"C:/Users/ht20/Documents/GitHub/NIST_testbeds/Seaside/\"\n",
        "DYNAMIC_PARAMS = {'TYPE': 'incore', 'RETURN': 'step_function', 'TESTBED': 'seaside',\n",
        "                  'OUT_DIR': ROOT_DISLOC + 'Dislocation_models/',\n",
        "                  'POP_DISLOC_DATA': ROOT_DISLOC + 'Dislocation_models/',\n",
        "                  'MAPPING': {'POWER': ROOT_DISLOC + 'Power/bldgs2elec_Seaside.csv',\n",
        "                              'WATER': ROOT_DISLOC + 'Water/bldgs2wter_Seaside.csv'}}\n",
        "EXTRA_COMMODITY = {1: ['PW'], 3: []}"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set analysis parameters \n",
        "1. `RC`: list of resource caps or the number of available resources in each step of the analysis. Each item of the list \n",
        "is a dictionary whose items show the type of resource and the available number of that type of resource. For example:\n",
        "    * If `FAIL_SCE_PARAM[TYPE']`=*from_csv*, you have two options:\n",
        "    * if, for example, `R_c`= [{'budget': 3}, {'budget': 6}], then the analysis is done for the cases\n",
        "    when there are 3 and 6 resources available of type 'budget' (total resource assignment).\n",
        "    * if, for example, `R_c`= [{'budget': {1:1, 2:1}}, {'budget': {1:1, 2:2}}, {'budget': {1:3, 2:3}}] and given there \n",
        "    are 2 layers, then the analysis is done for the case where each layer gets 1 resource of type 'budget', AND\n",
        "    the case where layer 1 gets 1 and layer 2 gets 2 resources of type 'budget', AND \n",
        "    the case where each layer gets 3 resource of type 'budget' (Prescribed resource for each layer).\n",
        "2. `LAYERS`: list of layers in the analysis. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "RC = [{'budget': 120000, 'time': 70}]\n",
        "# Prescribed for each layer -> RC = [{'budget':{1:60000, 3:700}, 'time':{1:2, 3:10}}]\n",
        "LAYERS = [1, 3]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " \n",
        "## Run method(s)\n",
        "There are two choices of method:\n",
        "1. `INDP`: runs Interdependent Network Restoration Problem (INDP). To run this method, you have to call:<br>\n",
        "`runutils.run_method(FAIL_SCE_PARAM, RC, LAYERS, method='INDP', output_dir=OUTPUT_DIR,\n",
        "misc = {'DYNAMIC_PARAMS':DYNAMIC_PARAMS})`\n",
        "2. `TDINDP`: runs time-dependent INDP (td-INDP). To run this method, you have to call:<br>\n",
        "`runutils.run_method(FAIL_SCE_PARAM, RC, LAYERS, method='TDINDP', output_dir=OUTPUT_DIR,\n",
        "misc = {'DYNAMIC_PARAMS':DYNAMIC_PARAMS}))`\n",
        "\n",
        "In both cases, if 'TIME_RESOURCE' is True, then the repair time for each element is considered in devising the \n",
        "restoration plans "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "runutils.run_method(FAIL_SCE_PARAM, RC, LAYERS, method='INDP', output_dir=OUTPUT_DIR,\n",
        "                    misc={'DYNAMIC_PARAMS': None, 'EXTRA_COMMODITY': EXTRA_COMMODITY, 'TIME_RESOURCE': True})\n",
        "runutils.run_method(FAIL_SCE_PARAM, RC, LAYERS, method='INDP', output_dir=OUTPUT_DIR,\n",
        "                    misc={'DYNAMIC_PARAMS': DYNAMIC_PARAMS, 'EXTRA_COMMODITY': EXTRA_COMMODITY, 'TIME_RESOURCE': True})\n",
        "# runutils.run_method(FAIL_SCE_PARAM, RC, LAYERS, method='TDINDP', output_dir=OUTPUT_DIR,\n",
        "#                     misc={'DYNAMIC_PARAMS': DYNAMIC_PARAMS, 'EXTRA_COMMODITY': EXTRA_COMMODITY, 'TIME_RESOURCE': True})"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " \n",
        "## Post-processing \n",
        "First, you have to set a few parameters and then call functions that read outputs\n",
        "and generate the pandas DataFrames that are needed for plotting the results.\n",
        "\n",
        "### Post-processing parameters \n",
        "1. `COST_TYPES`: type of cost that should be used in processing the outputs. Options \n",
        "are *Total*, *Under Supply*, *Over Supply*, *Node*, *Arc*, *Flow*, *Space Prep*, *Under Supply Perc*. \n",
        "2. `METHOD_NAMES`: methods whose output should be read. Options: `indp` (with static demand), `dp_indp` (with dynamic \n",
        "demand), `tdindp`, `dp_tdindp`. \n",
        "\n",
        "### Post-processing functions\n",
        "1. `generate_combinations`: generate all the combination of outputs that should be read and\n",
        "save them in `COMBS` and `OPTIMAL_COMBS` lists.\n",
        "2. `read_results`: read results for combinations in `COMBS` and `OPTIMAL_COMBS` lists.\n",
        "3. `read_run_time`: compute run time for different combinations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "COST_TYPES = ['Total']\n",
        "METHOD_NAMES = ['indp', 'dp_indp']\n",
        "COMBS, OPTIMAL_COMBS = dindputils.generate_combinations(FAIL_SCE_PARAM['TYPE'], FAIL_SCE_PARAM['MAGS'],\n",
        "                                                        FAIL_SCE_PARAM['SAMPLE_RANGE'], LAYERS, RC, METHOD_NAMES)\n",
        "BASE_DF, objs = dindputils.read_results(COMBS, OPTIMAL_COMBS, COST_TYPES, root_result_dir=OUTPUT_DIR, deaggregate=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save Variables to file\n",
        "All dictionaries that are made in the postprocessing step are saved here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "OBJ_LIST = [COMBS, OPTIMAL_COMBS, BASE_DF, METHOD_NAMES]\n",
        "with open(OUTPUT_DIR + 'postprocess_dicts.pkl', 'wb') as f:\n",
        "    pickle.dump(OBJ_LIST, f)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot results \n",
        "Plot functions use the dictionaries that are made in the postprocessing step to \n",
        "make output figures:\n",
        "1. `plot_performance_curves`: plots costs (in `COST_TYPES`) and unmet demand vs. time.\n",
        "2. `plot_separated_perform_curves`: plots costs (in `COST_TYPES`) vs. time for each layer sepearately."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### Getting back the objects ###\n",
        "with open(OUTPUT_DIR + 'postprocess_dicts.pkl', 'rb') as f:\n",
        "    [COMBS, OPTIMAL_COMBS, BASE_DF, METHOD_NAMES] = pickle.load(f)\n",
        "# plots.plot_performance_curves(BASE_DF, cost_type='Total', ci=None, deaggregate=False, plot_resilience=True)\n",
        "plots.plot_separated_perform_curves(BASE_DF, x='t', y='cost', cost_type='Total', ci=95, normalize=False)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}